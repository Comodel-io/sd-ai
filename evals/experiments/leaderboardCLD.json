{
    "engineConfigs": {
        "causal-chains-o4-mini": {
            "engine": "causal-chains",
            "additionalParameters": {
                "underlyingModel": "o4-mini"
            },
            "limits": {
                "baselineTokenUsage": 10000
            }
        },

         "causal-chains-gpt-4.1": {
            "engine": "causal-chains",
            "additionalParameters": {
                "underlyingModel": "gpt-4.1"
            },
            "limits": {
                "baselineTokenUsage": 10000
            }
        },

         "causal-chains-gemini-2.5-flash": {
            "engine": "causal-chains",
            "additionalParameters": {
                "underlyingModel": "gemini-2.5-flash"
            },
            "limits": {
                "tokensPerMinute": 90000,
                "requestsPerMinute": 10
            }
        },
        
        "recursivecausal-o4-mini": {
            "engine": "recursivecausal",
            "additionalParameters": {
                "underlyingModel": "o4-mini",
                "depth": 1
            },
            "limits": {
                "baselineTokenUsage": 10000,
                "requestsPerMinute": 1
            }
        },

        "recursivecausal-gpt-4.1": {
            "engine": "recursivecausal",
            "additionalParameters": {
                "underlyingModel": "gpt-4.1",
                "depth": 1
            },
            "limits": {
                "baselineTokenUsage": 10000,
                "requestsPerMinute": 1
            }
        },

        "recursivecausal-gemini-2.5-flash": {
            "engine": "recursivecausal",
            "additionalParameters": {
                "underlyingModel": "gemini-2.5-flash",
                "depth": 1
            },
            "limits": {
                "tokensPerMinute": 90000,
                "requestsPerMinute": 1
            }
        },

        "qualitative-o4-mini": {
            "engine": "qualitative",
            "additionalParameters": {
                "underlyingModel": "o4-mini"
            },
            "limits": {
                "baselineTokenUsage": 10000
            }
        },

        "qualitative-gpt-4.1": {
            "engine": "qualitative",
            "additionalParameters": {
                "underlyingModel": "gpt-4.1"
            },
            "limits": {
                "baselineTokenUsage": 10000
            }
        },

        "qualitative-gemini-2.5-flash": {
            "engine": "qualitative",
            "additionalParameters": {
                "underlyingModel": "gemini-2.5-flash"
            },
            "limits": {
                "tokensPerMinute": 90000,
                "requestsPerMinute": 10
            }
        }
    },
    "categories": {
        "causalTranslation": true,
        "conformance": true
    }
}
